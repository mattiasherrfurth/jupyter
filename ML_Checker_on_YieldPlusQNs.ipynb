{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxsDf88BoOPR"
   },
   "source": [
    "# Purpose\n",
    "\n",
    "- this notebook analyzes dataframes to determine how applicable they are for machine learning\n",
    "- there are many functions for creating and testing different dataframe transformations to apply clasifications to them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxsDf88BoOPR"
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IByu01VoIzt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import pyodbc\n",
    "from seaborn import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# GRIDSEARCH\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# SCORING\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             accuracy_score,\n",
    "                             mean_squared_error,\n",
    "                             r2_score)\n",
    "# TEXT HANDLING\n",
    "from sklearn.feature_extraction.text import (CountVectorizer,\n",
    "                                             HashingVectorizer,\n",
    "                                             TfidfVectorizer)\n",
    "# ENCODINGS\n",
    "from sklearn.preprocessing import (Binarizer,\n",
    "                                   FunctionTransformer,\n",
    "                                   LabelBinarizer,\n",
    "                                   PolynomialFeatures,\n",
    "                                   RobustScaler)\n",
    "# LINEAR CLASSIFICATIONS\n",
    "from sklearn.linear_model import (LinearRegression,\n",
    "                                  Ridge,\n",
    "                                  Lasso,\n",
    "                                  ElasticNet,\n",
    "                                  LogisticRegression)\n",
    "# NON-LINEAR CLASSIFICATIONS\n",
    "from sklearn.tree import (DecisionTreeRegressor,\n",
    "                          DecisionTreeClassifier)\n",
    "from sklearn.neighbors import (KNeighborsRegressor,\n",
    "                               KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4SOMwPVD6xWH"
   },
   "source": [
    "# VECTORIZATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8pQfQCXefb3"
   },
   "outputs": [],
   "source": [
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: vectorized dataframe with the target untouched\n",
    "# Vectorization = CountVectorizer\n",
    "def CntVec(df,target):\n",
    "    # split into X and y datasets\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    # extract numerical and object columns from X dataset\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    X_num = X_init.select_dtypes(include=numerics)\n",
    "    X_obj = X_init.select_dtypes(include='object')\n",
    "    # fill an empty dataframe with all the vectorizations of the object columns\n",
    "    X_vect = pd.DataFrame()\n",
    "    print('Count vectorizing...')\n",
    "    for col in X_obj.columns:\n",
    "        vect = CountVectorizer(binary=True)\n",
    "        arr = vect.fit_transform(X_obj[col]).toarray()\n",
    "        dfv = pd.DataFrame(arr)\n",
    "        X_vect = pd.concat([X_vect, dfv], axis=1, join_axes=[dfv.index])\n",
    "    # concat the vectorized data and the numeric data\n",
    "    X_prime = pd.concat([X_vect, X_num], axis=1, join_axes=[X_num.index])\n",
    "    # drop any NaNs that may have been made (there were few in the landslides vectorization)\n",
    "    nadrop = pd.concat([X_prime, y_init], axis=1, join_axes=[y_init.index]).dropna()\n",
    "    print('The vectorized data has shape:',nadrop.shape,'\\n')\n",
    "    return nadrop\n",
    "\n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: vectorized dataframe with the target untouched\n",
    "# Vectorization = TfidfVectorizer\n",
    "def TfdVec(df,target):\n",
    "    # split into X and y datasets\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    # extract numerical and object columns from X dataset\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    X_num = df.select_dtypes(include=numerics)\n",
    "    X_obj = df.select_dtypes(include='object')\n",
    "    # fill an empty dataframe with all the vectorizations of the object columns\n",
    "    X_vect = pd.DataFrame()\n",
    "    print('Tfidf vectorizing...')\n",
    "    for col in X_obj.columns:\n",
    "        vect = TfidfVectorizer()\n",
    "        arr = vect.fit_transform(X_obj[col].values.astype('U')).toarray()\n",
    "        df = pd.DataFrame(arr)\n",
    "        X_vect = pd.concat([X_vect, df], axis=1, join_axes=[df.index]).dropna()\n",
    "    # concat the vectorized data and the numeric data\n",
    "    X_prime = pd.concat([X_vect, X_num], axis=1, join_axes=[X_num.index])\n",
    "    # drop any NaNs that may have been made (there were few in the landslides vectorization)\n",
    "    nadrop = pd.concat([X_prime, y_init], axis=1, join_axes=[y_init.index]).dropna()\n",
    "    print('The vectorized data has shape:',nadrop.shape,'\\n')\n",
    "    return nadrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18wD9aG76qTm"
   },
   "source": [
    "# ENCODING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9luwVW96cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 1\n",
      "here 2\n"
     ]
    }
   ],
   "source": [
    "# INPUT: pandas dataframe\n",
    "# OUTPUT: dataframe with RobustScaler applied\n",
    "# Encoding = RobustScaler\n",
    "def RobScale(df):\n",
    "    dum = RobustScaler(with_centering=False)\n",
    "    print('Robust fitting...')\n",
    "    fit = dum.fit(df)\n",
    "    print('Robust scaling...')\n",
    "    df2 = fit.transform(df)\n",
    "    print('Pandas filling...')\n",
    "    dfit = pd.DataFrame(df2).dropna()\n",
    "    print('The scaled data has shape:',dfit.shape,'\\n')\n",
    "    return dfit\n",
    "\n",
    "print('here 1')\n",
    "\n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: robust scaled and encoded dataframe with the target untouched\n",
    "# Encoding = Binarizer\n",
    "def Binz(df, target):\n",
    "    # split into X and y datasets\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    dum = Binarizer()\n",
    "    scaled = RobScale(df)\n",
    "    print('Binarizer fitting...')\n",
    "    fit = dum.fit(scaled)\n",
    "    print('Binarizer transforming...')\n",
    "    dfit = pd.DataFrame(fit.transform(scaled))\n",
    "    # drop any NaNs that may have been made (there were few in the landslides vectorization)\n",
    "    dfity = pd.concat([dfit, y_init], axis=1, join_axes=[y_init.index]).dropna()\n",
    "    print('The encoded data has shape:',dfity.shape,'\\n\\n')\n",
    "    return dfity\n",
    "\n",
    "print('here 2')\n",
    "\n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: robust scaled and encoded dataframe with the target untouched\n",
    "# Encoding = FunctionTransformer\n",
    "def FncTran(df, target):\n",
    "    # split into X and y datasets\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    dum = FunctionTransformer()\n",
    "    scaled = RobScale(X_init)\n",
    "    print('Function transformer fitting...')\n",
    "    fit = dum.fit(scaled)\n",
    "    print('Function transforming...')\n",
    "    dfit = pd.DataFrame(fit.transform(scaled))\n",
    "    # drop any NaNs that may have been made (there were few in the landslides vectorization)\n",
    "    dfity = pd.concat([dfit, y_init], axis=1, join_axes=[y_init.index]).dropna()\n",
    "    print('The encoded data has shape:',dfity.shape,'\\n\\n')\n",
    "    return dfity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkDmgEtgplZ9"
   },
   "source": [
    "# LINEAR CLASSIFICATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMVRiWbRl_ZF"
   },
   "outputs": [],
   "source": [
    "### BACKUP LINES FOR ACCURACY SCORE AND CONFUSION\n",
    "#   acc_score = accuracy_score(y_test, pred.predict(X_test))  \n",
    "#   conf_matrix = confusion_matrix(y_test, pred.predict(X_test))\n",
    "#   print('The accuracy score is: \\t\\t%s'%acc_score)\n",
    "#   print('The confusion matrix is:',conf_matrix)\n",
    "\n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = LinearRegression\n",
    "def LinReg(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = LinearRegression()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred\n",
    "  \n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = LogisticRegression\n",
    "def LogReg(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = LogisticRegression()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred\n",
    "\n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = Ridge\n",
    "def RidgeClass(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = Ridge()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred\n",
    "  \n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = Lasso\n",
    "def LassoClass(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = Lasso()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred\n",
    "  \n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = ElasticNet\n",
    "def ElastNet(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = ElasticNet()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkDmgEtgplZ9"
   },
   "source": [
    "# NON-LINEAR CLASSIFICATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMVRiWbRl_ZF"
   },
   "outputs": [],
   "source": [
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = DecisionTreeRegressor\n",
    "def TreeReg(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = DecisionTreeRegressor()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred\n",
    "  \n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = DecisionTreeClassifier\n",
    "def TreeClass(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = DecisionTreeClassifier()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred\n",
    "\n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = KNeighborsRegressor\n",
    "def KNNReg(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = KNeighborsRegressor()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred\n",
    "\n",
    "# INPUT: pandas dataframe and the string representation of the target column\n",
    "# OUTPUT: predictive model based on the dataframe\n",
    "# Model = KNeighborsClassifier\n",
    "def KNNClass(df,target):\n",
    "    X_init = df.drop(target, axis=1)\n",
    "    y_init = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_init,y_init,train_size=0.7,random_state=42)\n",
    "    pred = KNeighborsClassifier()\n",
    "    pred.fit(X_train, y_train)\n",
    "    msq = mean_squared_error(y_test, pred.predict(X_test))\n",
    "    r2= r2_score(y_test, pred.predict(X_test))\n",
    "    print('The mean squared error is: \\t\\t%s'%msq)\n",
    "    print('The R2 score is: \\t\\t\\t%s'%r2)\n",
    "    return pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwtCcxE8H8Ql"
   },
   "source": [
    "# GETTING THE DATA\n",
    "- We are going to look at a dataset of landslides\n",
    "- This could be interesting, or boring. Not sure yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4_CtmwWNJyky"
   },
   "outputs": [],
   "source": [
    "## Past Year of YieldPlusQNs for BWI ##\n",
    "# connecting to the database\n",
    "cnxn_fttiy = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=EIM-DB-AG40.NORTHGRUM.COM;'\n",
    "                      'Database=j20032_yield;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "# defining the sql query string\n",
    "# NOTE: string is surrounded by three double-quotes (\"\"\"<text>\"\"\"), must exclude \"\"\" from query\n",
    "sql_fttiy = \"\"\"\n",
    "SELECT * \n",
    "    FROM [j20032_yield].[dbo].[YieldPlusQNs] \n",
    "        WHERE [DATE] >= DATEADD(Year, -1, getdate()) \n",
    "            AND [OROP_PLNT_ID] = 'P001'\n",
    "            \"\"\"\n",
    "df = pd.read_sql(sql_fttiy,cnxn_fttiy)\n",
    "\n",
    "# getting rid of any trailing whitespace\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = df[col].apply(lambda row: row.strip())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwtCcxE8H8Ql"
   },
   "source": [
    "# DESCRIPTIVE TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KiuflZOUPyoi"
   },
   "outputs": [],
   "source": [
    "# # useful descriptive tools\n",
    "# df.head()\n",
    "# df.shape\n",
    "# df.dtypes\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwtCcxE8H8Ql"
   },
   "source": [
    "# ANALYSIS TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting a dictionary with counts of unique elements in each columns\n",
    "# unq_cnts = []\n",
    "# for x in df.columns:\n",
    "#     unq_cnts = unq_cnts + [{'cols':x,'cnts':df[x].unique().shape[0]}]\n",
    "\n",
    "# # making countplots for each column with less than 50 unique values, counting the number of instances of each variable\n",
    "# for col in df.columns:\n",
    "#     if df[col].unique().shape[0] < 50:\n",
    "#         sns.countplot(data=df, y=col, palette='Blues_r', order=df[col].value_counts().index)\n",
    "#         plt.show()\n",
    "\n",
    "# # sorting the dictionary of unique counts\n",
    "# # columns with the fewest unique values are better targets\n",
    "# col_unqs = sorted(unq_cnts, key = lambda i: i['cnts'])\n",
    "# targ_cols = col_unqs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VvgnTtwPwUtZ"
   },
   "source": [
    "# DATA PREPARATION TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dropping nan values\n",
    "# df = df.dropna(axis=0, subset=['landslide_size'])\n",
    "\n",
    "# # example for creating dictonary of what to fill nans with in each column\n",
    "# values = {'admin_division_name': 'unknown', 'admin_division_population': df.admin_division_population.median(), 'country_code': 'UNK', \n",
    "#           'country_name': 'NA', 'created_date':'2017-11-20T15:17:00.000', 'event_description':'NA', \n",
    "#           'fatality_count':df.fatality_count.median(),'gazeteer_closest_point':'NA', \n",
    "#           'gazeteer_distance':df.gazeteer_distance.median(), 'injury_count':df.injury_count.median(), 'landslide_setting':'NA', 'landslide_trigger':'NA',\n",
    "#           'location_accuracy':'unknown', 'location_description':'NA', 'notes':'NA', 'photo_link':'NA', 'source_link':'NA', 'storm_name':'NA', 'submitted_date':'NA'}\n",
    "# df = df.fillna(value=values)\n",
    "\n",
    "# # example for numerizing the target\n",
    "# mapping = {'small':1, 'medium':2, 'large':3, 'very_large':4, 'catastrophic':5}\n",
    "# df = df.replace({'landslide_size':mapping})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8sN67ERxIIy"
   },
   "source": [
    "# BEGIN ANALYZING THE DATA\n",
    "- the functions for ML tools have been tested and are ready for use\n",
    "- need to define target before anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FjeXbrQpdd3"
   },
   "outputs": [],
   "source": [
    "target = 'landslide_size'\n",
    "fdsfsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kw4qRVuLpda0"
   },
   "outputs": [],
   "source": [
    "# vectorizations\n",
    "\n",
    "C_vect = CntVec(df, target)\n",
    "T_vect = TfdVec(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3V63VH1pdYN"
   },
   "outputs": [],
   "source": [
    "# encodings\n",
    "\n",
    "CntFnc = FncTran(C_vect, target)\n",
    "TfdFnc = FncTran(T_vect, target)\n",
    "CntBin = Binz(C_vect, target)\n",
    "TfdBin = Binz(T_vect, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEZHPwiUpdVg"
   },
   "outputs": [],
   "source": [
    "# # classifications\n",
    "\n",
    "print('\\n\\n**** MODEL = LINEAR REGRESSION *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncLin = LinReg(CntFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "TfdFncLin = LinReg(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinLin = LinReg(CntBin,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "TfdBinLin = LinReg(TfdBin,target)\n",
    "\n",
    "print('\\n\\n**** MODEL = LOGISTIC REGRESSION *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncLog = LogReg(CntFnc,target)\n",
    "#print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "#TfdFncLog = LogReg(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinLog = LogReg(CntBin,target)\n",
    "#print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "#TfdBinLog = LogReg(TfdBin,target)\n",
    "\n",
    "print('\\n\\n**** MODEL = RIDGE CLASSIFIER *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncRidge = RidgeClass(CntFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "TfdFncRidge = RidgeClass(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinRidge = RidgeClass(CntBin,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "TfdBinRidge = RidgeClass(TfdBin,target)\n",
    "\n",
    "print('\\n\\n**** MODEL = LASSO CLASSIFIER *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncLasso = LassoClass(CntFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "TfdFncLasso = LassoClass(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinLasso = LassoClass(CntBin,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "TfdBinLasso = LassoClass(TfdBin,target)\n",
    "\n",
    "print('\\n\\n**** MODEL = ELASTIC NET *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncElast = ElastNet(CntFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "TfdFncElast = ElastNet(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinElast = ElastNet(CntBin,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "TfdBinElast = ElastNet(TfdBin,target)\n",
    "\n",
    "print('\\n\\n**** MODEL = DECISION TREE REGRESSOR *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncTreeReg = TreeReg(CntFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "TfdFncTreeReg = TreeReg(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinTreeReg = TreeReg(CntBin,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "TfdBinTreeReg = TreeReg(TfdBin,target)\n",
    "\n",
    "print('\\n\\n**** MODEL = DECISION TREE CLASSIFIER *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncTreeClass = TreeClass(CntFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "TfdFncTreeClass = TreeClass(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinTreeClass = TreeClass(CntBin,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "TfdBinTreeClass = TreeClass(TfdBin,target)\n",
    "\n",
    "print('\\n\\n**** MODEL = KNN REGRESSOR *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncKNNReg = KNNReg(CntFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "TfdFncKNNReg = KNNReg(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinKNNReg = KNNReg(CntBin,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "TfdBinKNNReg = KNNReg(TfdBin,target)\n",
    "\n",
    "print('\\n\\n**** MODEL = KNN CLASSIFIER *********************')\n",
    "print('\\n\\tFEATURE ENGINEERING = CountVectorizer + FunctionTransformer')\n",
    "CntFncKNNClass = KNNClass(CntFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + FunctionTransformer')\n",
    "TfdFncKNNClass = KNNClass(TfdFnc,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = CountVectorizer + Binarizer')\n",
    "CntBinKNNClass = KNNClass(CntBin,target)\n",
    "print('\\n\\n\\tFEATURE ENGINEERING = TfidfVectorizer + Binarizer')\n",
    "TfdBinKNNClass = KNNClass(TfdBin,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72NyJ7TQ-uc_"
   },
   "source": [
    "# Notes on Classifications\n",
    "- the r2 score doesn't help us much unless we are talking about linear/logistic regression\n",
    "- the mean squared error is always helpful, identifying how far our samples are on average from the model\n",
    "\n",
    "# RESULTS\n",
    "- based on the mean squared error we can see that:\n",
    "  - Lasso and ElasticNet models predict with highest accuracy\n",
    "  - the two vectorizations for these two classifications produce Lasso/ENet models with similar accuracy\n",
    "  - the Binarizer produces a slightly more accurate Lasso/ENet model than the FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6mdb6JyWSQe"
   },
   "source": [
    "# GRID SEARCHING\n",
    "- picking the following combination of methods to include in the pipeline:\n",
    "  - CountVectorizer\n",
    "  - Binarizer\n",
    "  - RobustScaler\n",
    "  - ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZjupSeB-Y36"
   },
   "outputs": [],
   "source": [
    "# REFRESHING THE DATA SOURCE\n",
    "\n",
    "import urllib.request, json \n",
    "with urllib.request.urlopen(\"https://data.nasa.gov/resource/tfkf-kniw.json\") as url:\n",
    "    df = pd.DataFrame(json.loads(url.read().decode()))\n",
    "\n",
    "# what if we implemented the vectorization here?...\n",
    "for x in df.columns:\n",
    "  try:\n",
    "    df[x] = df[x].astype('float')\n",
    "  except ValueError:\n",
    "    pass\n",
    "    \n",
    "# we'll have to fill nans, remove unknowns in all data columns\n",
    "df = df.dropna(axis=0, subset=['landslide_size'])[df['landslide_size'] != 'unknown']\n",
    "\n",
    "# creating dictonary of what to fill nans with in each column\n",
    "values = {'admin_division_name': 'unknown', 'admin_division_population': df.admin_division_population.median(), 'country_code': 'UNK', \n",
    "          'country_name': 'NA', 'created_date':'2017-11-20T15:17:00.000', 'event_description':'NA', 'event_import_id': df.event_import_id.mean(), \n",
    "          'event_import_source': 'NA', 'fatality_count':df.fatality_count.median(),'gazeteer_closest_point':'NA', \n",
    "          'gazeteer_distance':df.gazeteer_distance.median(), 'injury_count':df.injury_count.median(), 'landslide_setting':'NA', 'landslide_trigger':'NA',\n",
    "          'location_accuracy':'unknown', 'location_description':'NA', 'notes':'NA', 'photo_link':'NA', 'source_link':'NA', 'storm_name':'NA', 'submitted_date':'NA'}\n",
    "df = df.fillna(value=values)\n",
    "\n",
    "# we have to numerize the target\n",
    "mapping = {'small':1, 'medium':2, 'large':3, 'very_large':4, 'catastrophic':5}\n",
    "df = df.replace({'landslide_size':mapping})\n",
    "\n",
    "# dropping unnecessary columns\n",
    "cols = ['source_link','created_date','submitted_date','photo_link','event_description']\n",
    "df = df.drop(columns=cols)\n",
    "\n",
    "# vectorizing the data\n",
    "df = CntVec(df, 'landslide_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99aCcoBA5eTd"
   },
   "outputs": [],
   "source": [
    "target = 'landslide_size'\n",
    "\n",
    "X = df.drop(target, axis=1).as_matrix()\n",
    "y = df[target].as_matrix()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zr8jTTlXWRso"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('rs', RobustScaler()),\n",
    "    ('binz', Binarizer()),\n",
    "    ('en', ElasticNet())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3tQlT32j5Ia"
   },
   "outputs": [],
   "source": [
    "# LITTLE SEARCH\n",
    "\n",
    "parameters = {'rs__with_centering':[True],\n",
    "              'rs__with_scaling':[True],\n",
    "#               'rs__copy':[True,False],\n",
    "#               'binz__copy':[True,False],\n",
    "              'binz__threshold':[3.15,3.2,3.25,3.3],\n",
    "              'en__alpha':[0.0,0.5],\n",
    "#               'en__l1_ratio':[0.0,0.25],\n",
    "              'en__fit_intercept':[True,False],\n",
    "              'en__normalize':[True,False],\n",
    "#               'en__precompute':[True,False],\n",
    "#               'en__warm_start':[True,False],\n",
    "#               'en__positive':[True,False]\n",
    "             }\n",
    "\n",
    "search = GridSearchCV(pipeline, parameters, cv=5,n_jobs=-1, verbose=3)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1x7tAvTFMVi"
   },
   "outputs": [],
   "source": [
    "# # BIG SEARCH\n",
    "\n",
    "# parameters = {'rs__with_centering':[True],\n",
    "#               'rs__with_scaling':[True],\n",
    "#               'rs__copy':[True,False],\n",
    "#               'binz__copy':[True,False],\n",
    "#               'binz__threshold':[3.15,3.2,3.25,3.3],\n",
    "#               'en__alpha':[0.0,0.5],\n",
    "#               'en__l1_ratio':[0.0,0.25],\n",
    "#               'en__fit_intercept':[True,False],\n",
    "#               'en__normalize':[True,False],\n",
    "#               'en__precompute':[True,False],\n",
    "#               'en__warm_start':[True,False],\n",
    "#               'en__positive':[True,False]\n",
    "#              }\n",
    "\n",
    "# search = GridSearchCV(pipeline, parameters, cv=5,n_jobs=-1, verbose=3)\n",
    "# search.fit(X_train, y_train)\n",
    "# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "# print(search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "CpbQODLfva4Z",
    "72NyJ7TQ-uc_"
   ],
   "name": "landslides_v21.ipynb",
   "provenance": [
    {
     "file_id": "11C3lyN4Hrd70YvQQu6dc2qeuDVcEJlED",
     "timestamp": 1558109344044
    },
    {
     "file_id": "16jf7G9pi_2Cw1iLelQ0hh--cVF1KRAtN",
     "timestamp": 1557781160299
    },
    {
     "file_id": "1kf9NqOL0-i-7izZ53Km_J74QaqQF_Fc9",
     "timestamp": 1557774240137
    },
    {
     "file_id": "1szv1xtI3js41vIpXk5S-IQcnEN86O5uf",
     "timestamp": 1557770943769
    },
    {
     "file_id": "1JEDqT-UZPRQny1oOgDe4LXkzkTo6kKVF",
     "timestamp": 1557760537277
    },
    {
     "file_id": "1E9evRF1kgygNJbradilsDUDFG5O4VWJz",
     "timestamp": 1557709305126
    },
    {
     "file_id": "1b_Xg1T2jVD3fTSg7UC1wKNTaxNF29qEA",
     "timestamp": 1557707803216
    },
    {
     "file_id": "10fcw3FZhdKG8nPqKApTXdp7gtg2YZJXb",
     "timestamp": 1557705536532
    },
    {
     "file_id": "1Ndzjj6wi6-okTzIlbScYJBtUqq0Id9qx",
     "timestamp": 1557683738945
    },
    {
     "file_id": "19qQOSwdgIlJYXRbvWTDHEsre_JgEUnpI",
     "timestamp": 1557682236232
    },
    {
     "file_id": "1qB2gMjSC_SHSzQ9ATiY1b2j-iGS2hYcb",
     "timestamp": 1557679042220
    },
    {
     "file_id": "1c3s0Bk0KnwD1HnXiTyeFem4SrVWLrfqx",
     "timestamp": 1557677481116
    },
    {
     "file_id": "16neykyKvSsmIatolyrnvl0RBSaMnASxG",
     "timestamp": 1557635936370
    },
    {
     "file_id": "19pZM2SE3puZ5lGm8JAw89pvxBWwQGQlr",
     "timestamp": 1557617865825
    },
    {
     "file_id": "1f_kmPdkWXDkLuuDj63-1gZ2If_GUS-qU",
     "timestamp": 1557615568689
    },
    {
     "file_id": "13UW95ohq7nvZgvdS-CmhYVCCDVAWKeZU",
     "timestamp": 1557595266025
    },
    {
     "file_id": "1VAcUgbiFDpsa8GhS7eJ2If838m6PKN0-",
     "timestamp": 1557587042418
    },
    {
     "file_id": "1hgQ8BiYr-g2sznHBV0jPESvteM3wmQqR",
     "timestamp": 1557584004626
    },
    {
     "file_id": "1ya6byg_lwiGFcMeovDs220exFcgcYfBP",
     "timestamp": 1557450793571
    },
    {
     "file_id": "1s7LjEV-TVDu94nAYZvNYLbgI4Lechbpv",
     "timestamp": 1557273257688
    },
    {
     "file_id": "1wc-OAysyLQqrXF6LdSuxJR8tOFdI8aHT",
     "timestamp": 1557196108302
    },
    {
     "file_id": "1dM8WFYbamd7J0mT9GH3HUbhsaA9BsjYZ",
     "timestamp": 1557104240111
    },
    {
     "file_id": "1PJEZ9Yjjt6KdcWRl4b77KUL-I8h6uGBD",
     "timestamp": 1557011313487
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
